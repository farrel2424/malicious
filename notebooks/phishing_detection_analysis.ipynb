{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17466125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/malicious_phish.csv')\n",
    "\n",
    "# Initial inspection\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['type'].value_counts().plot(kind='bar', color='steelblue')\n",
    "plt.title('Distribution of URL Types', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('URL Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Percentage distribution\n",
    "print(\"\\nPercentage Distribution:\")\n",
    "print(df['type'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(url):\n",
    "    \"\"\"Extract features from URL\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        \n",
    "        # Basic features\n",
    "        features['url_length'] = len(url)\n",
    "        features['domain_length'] = len(parsed.netloc)\n",
    "        features['path_length'] = len(parsed.path)\n",
    "        \n",
    "        # Special characters\n",
    "        features['num_dots'] = url.count('.')\n",
    "        features['num_hyphens'] = url.count('-')\n",
    "        features['num_underscores'] = url.count('_')\n",
    "        features['num_slashes'] = url.count('/')\n",
    "        features['num_questionmarks'] = url.count('?')\n",
    "        features['num_equals'] = url.count('=')\n",
    "        features['num_at'] = url.count('@')\n",
    "        features['num_ampersand'] = url.count('&')\n",
    "        features['num_exclamation'] = url.count('!')\n",
    "        features['num_space'] = url.count(' ')\n",
    "        features['num_tilde'] = url.count('~')\n",
    "        features['num_comma'] = url.count(',')\n",
    "        features['num_plus'] = url.count('+')\n",
    "        features['num_asterisk'] = url.count('*')\n",
    "        features['num_hashtag'] = url.count('#')\n",
    "        features['num_dollar'] = url.count('$')\n",
    "        features['num_percent'] = url.count('%')\n",
    "        \n",
    "        # URL components\n",
    "        features['has_ip'] = 1 if re.search(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', url) else 0\n",
    "        features['has_port'] = 1 if ':' in parsed.netloc and '@' not in parsed.netloc else 0\n",
    "        features['is_https'] = 1 if parsed.scheme == 'https' else 0\n",
    "        \n",
    "        # Digits and letters\n",
    "        features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "        features['num_letters'] = sum(c.isalpha() for c in url)\n",
    "        \n",
    "        # Suspicious patterns\n",
    "        features['has_suspicious_words'] = 1 if any(word in url.lower() for word in \n",
    "            ['login', 'signin', 'account', 'verify', 'secure', 'update', 'confirm', \n",
    "             'banking', 'paypal', 'ebay', 'amazon']) else 0\n",
    "        \n",
    "        # Domain features\n",
    "        domain_tokens = parsed.netloc.split('.')\n",
    "        features['num_subdomains'] = len(domain_tokens) - 2 if len(domain_tokens) > 2 else 0\n",
    "        \n",
    "        # Query parameters\n",
    "        features['num_params'] = len(parsed.query.split('&')) if parsed.query else 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fill with zeros if parsing fails\n",
    "        for key in features:\n",
    "            features[key] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply feature extraction\n",
    "print(\"Extracting features from URLs...\")\n",
    "features_df = df['url'].apply(extract_features).apply(pd.Series)\n",
    "features_df['type'] = df['type']\n",
    "\n",
    "print(\"\\nFeatures extracted:\")\n",
    "print(features_df.head())\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "correlation = features_df.drop('type', axis=1).corr()\n",
    "sns.heatmap(correlation, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with target\n",
    "# First encode target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "features_df['type_encoded'] = le.fit_transform(features_df['type'])\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = features_df.drop(['type'], axis=1).corrwith(features_df['type_encoded']).abs()\n",
    "top_features = correlations.sort_values(ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features.plot(kind='barh', color='teal')\n",
    "plt.title('Top 15 Features Correlated with Phishing', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee6432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for top features\n",
    "top_5_features = correlations.sort_values(ascending=False).head(5).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_5_features):\n",
    "    sns.boxplot(data=features_df, x='type', y=feature, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{feature} by URL Type')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f16498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# Prepare features and target\n",
    "X = features_df.drop(['type', 'type_encoded'], axis=1)\n",
    "y = features_df['type_encoded']\n",
    "\n",
    "# Split data (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for deployment\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "joblib.dump(le, '../models/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a42bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracies\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': results.keys(),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Training Time (s)': [results[m]['training_time'] for m in results]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], color='skyblue')\n",
    "axes[0].set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim([0.8, 1.0])\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Training time comparison\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['Training Time (s)'], color='salmon')\n",
    "axes[1].set_title('Training Time Comparison', fontweight='bold')\n",
    "axes[1].set_ylabel('Time (seconds)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (highest accuracy)\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = results[best_model_name]['y_pred']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, \n",
    "            yticklabels=le.classes_)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, '../models/best_model.pkl')\n",
    "print(f\"\\nBest model saved to '../models/best_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name in ['Random Forest', 'XGBoost']:\n",
    "    # Get feature importance\n",
    "    importance = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).head(15)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='green')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 15 Feature Importance - {best_model_name}', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
